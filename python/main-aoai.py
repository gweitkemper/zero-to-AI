"""
Usage:
  python main-aoai.py <func>
  python main-aoai.py check_env
  python main-aoai.py generate_embedding
  python main-aoai.py generate_completion
  python main-aoai.py generate_completion_with_md_prompt
Options:
  -h --help     Show this screen.
  --version     Show version.
"""

# Chris Joakim, 3Cloud/Cognizant, 2026

import asyncio
import sys
import os
import traceback

from pprint import pprint

from docopt import docopt
from dotenv import load_dotenv

import openai
from openai import AzureOpenAI
from openai.types import CreateEmbeddingResponse
from openai.types.chat.chat_completion import ChatCompletion

from src.ai.aoai_util import AOAIUtil
from src.io.fs import FS


def print_options(msg):
    print(msg)
    arguments = docopt(__doc__, version="1.0.0")
    print(arguments)


async def check_env():
    await asyncio.sleep(0.01)
    load_dotenv(override=True)
    for name in sorted(os.environ.keys()):
        if name.startswith("AZURE_OPENAI_"):
            print("{}: {}".format(name, os.environ[name]))


async def generate_embedding():
    ai_util = AOAIUtil()
    embedding = await ai_util.generate_embeddings("Hello, world!")
    print(embedding)


async def generate_completion():
    ai_util = AOAIUtil()
    system_context = "You are a helpful assistant who knows Major League Baseball."
    user_prompt = "What uniform number did Mickey Mantle wear?"
    completion = await ai_util.generate_completion(system_context, user_prompt)
    print(completion)


def generate_embedding_original():
    # See https://platform.openai.com/docs/guides/embeddings
    # See https://github.com/openai/openai-python/blob/main/src/openai/types/create_embedding_response.py

    url = os.getenv("AZURE_OPENAI_EMBEDDINGS_URL")
    key = os.getenv("AZURE_OPENAI_EMBEDDINGS_KEY")
    dep = os.getenv("AZURE_OPENAI_EMBEDDINGS_DEP")

    client = AzureOpenAI(azure_endpoint=url, api_key=key, api_version="2024-10-21")

    embedding: CreateEmbeddingResponse = client.embeddings.create(
        model=dep,  # your model deployment name
        input="Running marathons and ultramarathons",
        encoding_format="float",
    )

    print(embedding)
    vector = embedding.data[0].embedding
    print("Embedding: {}".format(vector))
    print("Model:  {}".format(embedding.model))
    print("Usage:  {}".format(embedding.usage))
    print("Length: {}".format(len(vector)))

    FS.write_json(vector, "tmp/embedding.json")

    # [ ... , -0.014864896]
    # Model:  text-embedding-ada-002
    # Usage:  Usage(prompt_tokens=9, total_tokens=9)
    # Length: 1536


def generate_completion_original():
    url = os.getenv("AZURE_OPENAI_COMPLETIONS_URL")
    key = os.getenv("AZURE_OPENAI_COMPLETIONS_KEY")
    dep = os.getenv("AZURE_OPENAI_COMPLETIONS_DEP")

    client = AzureOpenAI(azure_endpoint=url, api_key=key, api_version="2024-10-21")

    # <class 'openai.types.chat.chat_completion.ChatCompletion'>
    completion: ChatCompletion = client.chat.completions.create(
        model=dep,
        messages=[
            {
                "role": "system",
                "content": "You are a helpful assistant who knows Major League Baseball.",
            },
            {"role": "user", "content": "What uniform number did Mickey Mantle wear?"},
        ],
    )

    print("=== completion type ===")
    print(str(type(completion)))

    print("=== message ===")
    print(completion.choices[0].message)

    print("=== content ===")
    print(completion.choices[0].message.content)
    # Mickey Mantle wore the uniform number 7 for the New York Yankees throughout his Hall of Fame career.

    print("=== model_dump_json ===")
    print(completion.model_dump_json(indent=2))


def generate_completion_with_md_prompt():
    url = os.getenv("AZURE_OPENAI_COMPLETIONS_URL")
    key = os.getenv("AZURE_OPENAI_COMPLETIONS_KEY")
    dep = os.getenv("AZURE_OPENAI_COMPLETIONS_DEP")

    client = AzureOpenAI(azure_endpoint=url, api_key=key, api_version="2024-10-21")

    # <class 'openai.types.chat.chat_completion.ChatCompletion'>
    completion: ChatCompletion = client.chat.completions.create(
        model=dep,
        temperature=0.0,
        max_tokens=1000,
        messages=[
            {"role": "system", "content": text_summarization_md()},
            {"role": "user", "content": gettysburg_address_user_md()},
        ],
    )

    print("=== completion type ===")
    print(str(type(completion)))

    print("=== message ===")
    print(completion.choices[0].message)

    print("=== content ===")
    print(completion.choices[0].message.content)

    print("=== model_dump_json ===")
    print(completion.model_dump_json(indent=2))


def text_summarization_md():
    return """
## Purpose

You are a helpful assistant who summarizes text.

Summarize the following text into bullet points.

"""


def gettysburg_address_user_md():
    text = FS.read("../data/misc/gettysburg-address.txt").strip()
    return """
## Text to summarize

{}

""".format(text).lstrip()


def industrial_disease_lyrics_md():
    text = FS.read("../data/text/industrial_disease_lyrics.txt").strip()
    return """
## Text to summarize

{}

""".format(text).lstrip()


async def main():
    try:
        load_dotenv(override=True)
        func = sys.argv[1].lower()
        if func == "check_env":
            await check_env()
        elif func == "generate_embedding":
            await generate_embedding()
        elif func == "generate_completion":
            await generate_completion()
        elif func == "generate_completion_with_md_prompt":
            generate_completion_with_md_prompt()
        else:
            print_options("Error: invalid function: {}".format(func))
    except Exception as e:
        print(str(e))
        print(traceback.format_exc())


if __name__ == "__main__":
    # __main__ is the entry-point to the program when python is executed at the command-line
    # Use the asyncio.run() method to run the main() function asynchronously
    asyncio.run(main())
